{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4193c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "import time\n",
    "import threading\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Alpaca API credentials\n",
    "API_KEY = 'PKL0QPAXI2XEQN42OD2S'\n",
    "API_SECRET = 'nkqziIUvRn7rkEihNRVpw9IcNYftpDxVHPRQnyS3'\n",
    "BASE_URL = 'https://paper-api.alpaca.markets'\n",
    "\n",
    "# Initialize API\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, base_url=BASE_URL)\n",
    "\n",
    "# News data storage\n",
    "all_news = []\n",
    "\n",
    "# Define CSV file name\n",
    "csv_file = 'financial_news.csv'\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"FB\", \"INTC\", \"TSLA\", \"NVDA\", \"ORCL\", \"IBM\",\n",
    "    \"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\", \"AXP\", \"MS\", \"BRK.B\",\n",
    "    \"JNJ\", \"PFE\", \"UNH\", \"MRK\", \"ABBV\", \"TMO\", \"ABT\",\n",
    "    \"PG\", \"KO\", \"PEP\", \"NKE\", \"MO\",\n",
    "    \"GE\", \"MMM\", \"BA\", \"HON\", \"CAT\",\n",
    "    \"XOM\", \"CVX\", \"BP\", \"TOT\",\n",
    "    \"NEP\", \"DUK\", \"SO\",\n",
    "    \"T\", \"VZ\",\n",
    "    \"DIS\", \"MCD\", \"SBUX\",\n",
    "    \"WMT\", \"HD\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b6529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch news for a ticker\n",
    "def fetch_news(ticker):\n",
    "    global all_news\n",
    "    try:\n",
    "        news = api.get_news(symbol=ticker, limit=200)  # Adjust the limit as needed\n",
    "        \n",
    "        for article in news:\n",
    "            all_news.append({\n",
    "                'headline': article.headline,\n",
    "                'summary': article.summary,\n",
    "                'created_at': article.created_at,\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news for {ticker}: {e}\")\n",
    "\n",
    "# Function to process requests in batches\n",
    "def process_requests():\n",
    "    while tickers:\n",
    "        threads = []\n",
    "        for _ in range(200):  # 200 parallel threads, respecting the rate limit\n",
    "            if tickers:\n",
    "                ticker = tickers.pop(0)\n",
    "                thread = threading.Thread(target=fetch_news, args=(ticker,))\n",
    "                threads.append(thread)\n",
    "                thread.start()\n",
    "\n",
    "        # Wait for all threads to complete\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "        # Wait for 60 seconds before the next batch\n",
    "        time.sleep(60)\n",
    "\n",
    "# Write data to CSV\n",
    "def write_to_csv():\n",
    "    with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=all_news[0].keys())\n",
    "        writer.writeheader()\n",
    "        for news_item in all_news:\n",
    "            writer.writerow(news_item)\n",
    "\n",
    "    print(f'Data saved to {csv_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94112a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ea4b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Keep digits and symbols that can be significant in financial analysis. \n",
    "# E.g. digits could represent financial figures, and symbols like '$' might indicate currency amounts. \n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)  \n",
    "    # Remove newlines and tabs\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '').replace('\\t', ' ') \n",
    "#     # Keep words, digits, $ and .\n",
    "#     text = re.sub(r'[^\\w\\d$.]', ' ', text)  \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee86f8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             article  \\\n",
      "0  Stocks rallied, with AAPL reaching $150.50. Mo...   \n",
      "1  Q1 profits fell to $1.5 billion, down from $2 ...   \n",
      "2  Tech stocks, e.g., MSFT, AMZN, and GOOG, showe...   \n",
      "\n",
      "                                     cleaned_article  \n",
      "0  Stocks rallied, with AAPL reaching $150.50. Mo...  \n",
      "1  Q1 profits fell to $1.5 billion, down from $2 ...  \n",
      "2  Tech stocks, e.g., MSFT, AMZN, and GOOG, showe...  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing clean_data()\n",
    "'''\n",
    "# Example DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'article': [\"Stocks rallied, with AAPL reaching $150.50. More at http://example.com\", \n",
    "                \"Q1 profits fell to $1.5 billion, down from $2 billion. Visit http://finance.com for more.\", \n",
    "                \"Tech stocks, e.g., MSFT, AMZN, and GOOG, showed mixed results today.\"]\n",
    "})\n",
    "\n",
    "data['cleaned_article'] = data['article'].apply(clean_text)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0c2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def extract_date(date_str):\n",
    "    try:\n",
    "        # Parse the string to a datetime object\n",
    "        dt = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S+00:00')\n",
    "        # Format the datetime object to keep only the date part\n",
    "        return dt.strftime('%Y-%m-%d')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing date: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1fdbbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-25\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing extract_date()\n",
    "'''\n",
    "date_string = \"2024-01-25 13:37:00+00:00\"\n",
    "extracted_date = extract_date(date_string)\n",
    "print(extracted_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3e04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gather data and write to csv file\n",
    "# process_requests()\n",
    "# write_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44228403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ca6836c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>summary</th>\n",
       "      <th>created_at</th>\n",
       "      <th>headline_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meta Blocks Adults From Messaging Teens They D...</td>\n",
       "      <td>Meta Platforms has unveiled stricter messaging...</td>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>Meta Blocks Adults From Messaging Teens They D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After 130% Surge, AMD Faces Uncertain Road Ahe...</td>\n",
       "      <td>AMD&amp;#39;s stock surged in 2023 due to high dem...</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>After 130% Surge, AMD Faces Uncertain Road Ahe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legendary Investor Jim Rogers Predicts Market ...</td>\n",
       "      <td>Rogers has identified indicators of an impendi...</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>Legendary Investor Jim Rogers Predicts Market ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark Zuckerberg's Meta Said To Be Worried Abou...</td>\n",
       "      <td>This story was first published on the Benzinga...</td>\n",
       "      <td>2023-12-21</td>\n",
       "      <td>Mark Zuckerberg's Meta Said To Be Worried Abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Now, Facebook And Messenger Also Get End-To-En...</td>\n",
       "      <td>Meta&amp;#39;s new encryption feature implies that...</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>Now, Facebook And Messenger Also Get End-To-En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6797</th>\n",
       "      <td>Musk, Bezos, Buffett Get Richer, Rest Of World...</td>\n",
       "      <td>A new report highlights the inequality in weal...</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>Musk, Bezos, Buffett Get Richer, Rest Of World...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>Tesla Halts Model 3 Deliveries in Australia Ov...</td>\n",
       "      <td>Tesla has reportedly halted deliveries of its ...</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>Tesla Halts Model 3 Deliveries in Australia Ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>What's Going On With Tesla Stock?</td>\n",
       "      <td>Tesla shares appear to be facing selling press...</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>What's Going On With Tesla Stock? Tesla shares...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6800</th>\n",
       "      <td>Tesla Stock Falls Over 1% Premarket: What's Go...</td>\n",
       "      <td>The stock has been on a lean trot since mid-Ju...</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>Tesla Stock Falls Over 1% Premarket: What's Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6801</th>\n",
       "      <td>'AI Revolution' Key Narrative For Q4 Tech Earn...</td>\n",
       "      <td>Tech companies are likely to have good fourth-...</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>'AI Revolution' Key Narrative For Q4 Tech Earn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6802 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headline  \\\n",
       "0     Meta Blocks Adults From Messaging Teens They D...   \n",
       "1     After 130% Surge, AMD Faces Uncertain Road Ahe...   \n",
       "2     Legendary Investor Jim Rogers Predicts Market ...   \n",
       "3     Mark Zuckerberg's Meta Said To Be Worried Abou...   \n",
       "4     Now, Facebook And Messenger Also Get End-To-En...   \n",
       "...                                                 ...   \n",
       "6797  Musk, Bezos, Buffett Get Richer, Rest Of World...   \n",
       "6798  Tesla Halts Model 3 Deliveries in Australia Ov...   \n",
       "6799                  What's Going On With Tesla Stock?   \n",
       "6800  Tesla Stock Falls Over 1% Premarket: What's Go...   \n",
       "6801  'AI Revolution' Key Narrative For Q4 Tech Earn...   \n",
       "\n",
       "                                                summary  created_at  \\\n",
       "0     Meta Platforms has unveiled stricter messaging...  2024-01-25   \n",
       "1     AMD&#39;s stock surged in 2023 due to high dem...  2024-01-23   \n",
       "2     Rogers has identified indicators of an impendi...  2023-12-29   \n",
       "3     This story was first published on the Benzinga...  2023-12-21   \n",
       "4     Meta&#39;s new encryption feature implies that...  2023-12-07   \n",
       "...                                                 ...         ...   \n",
       "6797  A new report highlights the inequality in weal...  2024-01-17   \n",
       "6798  Tesla has reportedly halted deliveries of its ...  2024-01-17   \n",
       "6799  Tesla shares appear to be facing selling press...  2024-01-17   \n",
       "6800  The stock has been on a lean trot since mid-Ju...  2024-01-17   \n",
       "6801  Tech companies are likely to have good fourth-...  2024-01-17   \n",
       "\n",
       "                                       headline_summary  \n",
       "0     Meta Blocks Adults From Messaging Teens They D...  \n",
       "1     After 130% Surge, AMD Faces Uncertain Road Ahe...  \n",
       "2     Legendary Investor Jim Rogers Predicts Market ...  \n",
       "3     Mark Zuckerberg's Meta Said To Be Worried Abou...  \n",
       "4     Now, Facebook And Messenger Also Get End-To-En...  \n",
       "...                                                 ...  \n",
       "6797  Musk, Bezos, Buffett Get Richer, Rest Of World...  \n",
       "6798  Tesla Halts Model 3 Deliveries in Australia Ov...  \n",
       "6799  What's Going On With Tesla Stock? Tesla shares...  \n",
       "6800  Tesla Stock Falls Over 1% Premarket: What's Go...  \n",
       "6801  'AI Revolution' Key Narrative For Q4 Tech Earn...  \n",
       "\n",
       "[6802 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# def get_sentiment(text):\n",
    "#     sentiment = classifier(text)[0]  # Access the first element of the result\n",
    "\n",
    "#     if sentiment['label'] == 'POSITIVE':\n",
    "#         return f\"{sentiment['score']:.2f}\"  # Corrected format string\n",
    "\n",
    "#     return f\"-{sentiment['score']:.2f}\"  # Corrected format string\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Data cleaning\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['headline'] = df['headline'].apply(clean_text)\n",
    "df['summary'] = df['summary'].apply(clean_text)\n",
    "df['created_at'] = df['created_at'].apply(extract_date)\n",
    "df['headline_summary'] = df['headline'] + \" \" + df['summary']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20861f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\scsar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenisation\n",
    "df['tokens'] = df['headline_summary'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d86d83ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\scsar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['filtered_tokens'] = df['tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec98c0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\scsar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized'] = df['filtered_tokens'].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e66df72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword analysis\n",
    "\n",
    "def has_direct_impact(text, keywords):\n",
    "    return any(keyword.lower() in text.lower() for keyword in keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af11b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"yiyanghkust/finbert-tone\"  # Example FinBERT model\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create a sentiment analysis pipeline\n",
    "finbert = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Function to apply FinBERT to a batch of texts\n",
    "def apply_finbert_to_batch(texts):\n",
    "    results = finbert(texts)\n",
    "    labels = [result['label'] for result in results]\n",
    "    scores = [result['score'] for result in results]\n",
    "    return labels, scores\n",
    "\n",
    "# Batch processing function\n",
    "def process_in_batches(dataframe, column_name, batch_size=20):\n",
    "    num_batches = int(np.ceil(len(dataframe) / batch_size))\n",
    "    labels, scores = [], []\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batch_texts = dataframe[column_name].iloc[i * batch_size:(i + 1) * batch_size].tolist()\n",
    "        batch_labels, batch_scores = apply_finbert_to_batch(batch_texts)\n",
    "        labels.extend(batch_labels)\n",
    "        scores.extend(batch_scores)\n",
    "\n",
    "    return labels, scores\n",
    "\n",
    "df['sentiment_label'], df['sentiment_score'] = process_in_batches(df, 'headline_summary', batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_num = random.randint(1, 6000)\n",
    "print(df.iloc[test_num][0])\n",
    "print(df.iloc[test_num][1])\n",
    "print(df.iloc[test_num][-1])\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
