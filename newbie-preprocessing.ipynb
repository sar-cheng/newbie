{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4193c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "import time\n",
    "import threading\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Alpaca API credentials\n",
    "API_KEY = 'PKL0QPAXI2XEQN42OD2S'\n",
    "API_SECRET = 'nkqziIUvRn7rkEihNRVpw9IcNYftpDxVHPRQnyS3'\n",
    "BASE_URL = 'https://paper-api.alpaca.markets'\n",
    "\n",
    "# Initialize API\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, base_url=BASE_URL)\n",
    "\n",
    "# Main csv file\n",
    "csv_file = \"financial_news.csv\"\n",
    "\n",
    "# News data storage\n",
    "all_news = []\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"FB\", \"INTC\", \"TSLA\", \"NVDA\", \"ORCL\", \"IBM\",\n",
    "    \"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\", \"AXP\", \"MS\", \"BRK.B\",\n",
    "    \"JNJ\", \"PFE\", \"UNH\", \"MRK\", \"ABBV\", \"TMO\", \"ABT\",\n",
    "    \"PG\", \"KO\", \"PEP\", \"NKE\", \"MO\",\n",
    "    \"GE\", \"MMM\", \"BA\", \"HON\", \"CAT\",\n",
    "    \"XOM\", \"CVX\", \"BP\", \"TOT\",\n",
    "    \"NEP\", \"DUK\", \"SO\",\n",
    "    \"T\", \"VZ\",\n",
    "    \"DIS\", \"MCD\", \"SBUX\",\n",
    "    \"WMT\", \"HD\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67a416",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b6529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch news for a ticker\n",
    "def fetch_news(ticker):\n",
    "    global all_news\n",
    "    try:\n",
    "        news = api.get_news(symbol=ticker, limit=200)  # Adjust the limit as needed\n",
    "        \n",
    "        for article in news:\n",
    "            all_news.append({\n",
    "                'headline': article.headline,\n",
    "                'summary': article.summary,\n",
    "                'created_at': article.created_at,\n",
    "                'ticker': ticker\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news for {ticker}: {e}\")\n",
    "\n",
    "# Function to process requests in batches\n",
    "def process_requests():\n",
    "    while tickers:\n",
    "        threads = []\n",
    "        for _ in range(200):  # 200 parallel threads, respecting the rate limit\n",
    "            if tickers:\n",
    "                ticker = tickers.pop(0)\n",
    "                thread = threading.Thread(target=fetch_news, args=(ticker,))\n",
    "                threads.append(thread)\n",
    "                thread.start()\n",
    "\n",
    "        # Wait for all threads to complete\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "        # Wait for 60 seconds before the next batch\n",
    "        time.sleep(60)\n",
    "\n",
    "# Write data to CSV\n",
    "def write_to_csv():\n",
    "    with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=all_news[0].keys())\n",
    "        writer.writeheader()\n",
    "        for news_item in all_news:\n",
    "            writer.writerow(news_item)\n",
    "\n",
    "    print(f'Data saved to {csv_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9b915e",
   "metadata": {},
   "source": [
    "Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ea4b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Keep digits and symbols that can be significant in financial analysis. \n",
    "# E.g. digits could represent financial figures, and symbols like '$' might indicate currency amounts. \n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)  \n",
    "    # Remove newlines and tabs\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '').replace('\\t', ' ') \n",
    "#     # Keep words, digits, $ and .\n",
    "#     text = re.sub(r'[^\\w\\d$.]', ' ', text)  \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee86f8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             article  \\\n",
      "0  Stocks rallied, with AAPL reaching $150.50. Mo...   \n",
      "1  Q1 profits fell to $1.5 billion, down from $2 ...   \n",
      "2  Tech stocks, e.g., MSFT, AMZN, and GOOG, showe...   \n",
      "\n",
      "                                     cleaned_article  \n",
      "0  Stocks rallied, with AAPL reaching $150.50. Mo...  \n",
      "1  Q1 profits fell to $1.5 billion, down from $2 ...  \n",
      "2  Tech stocks, e.g., MSFT, AMZN, and GOOG, showe...  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing clean_data()\n",
    "'''\n",
    "# Example DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'article': [\"Stocks rallied, with AAPL reaching $150.50. More at http://example.com\", \n",
    "                \"Q1 profits fell to $1.5 billion, down from $2 billion. Visit http://finance.com for more.\", \n",
    "                \"Tech stocks, e.g., MSFT, AMZN, and GOOG, showed mixed results today.\"]\n",
    "})\n",
    "\n",
    "data['cleaned_article'] = data['article'].apply(clean_text)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0c2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def extract_date(date_str):\n",
    "    try:\n",
    "        # Parse the string to a datetime object\n",
    "        dt = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S+00:00')\n",
    "        # Format the datetime object to keep only the date part\n",
    "        return dt.strftime('%Y-%m-%d')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing date: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1fdbbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-25\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing extract_date()\n",
    "'''\n",
    "date_string = \"2024-01-25 13:37:00+00:00\"\n",
    "extracted_date = extract_date(date_string)\n",
    "print(extracted_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d72999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gather data and write to csv file\n",
    "# process_requests()\n",
    "# write_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a96421",
   "metadata": {},
   "source": [
    "Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca6836c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>summary</th>\n",
       "      <th>created_at</th>\n",
       "      <th>ticker</th>\n",
       "      <th>headline_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How We Missed A Winning Trade On IBM--And How ...</td>\n",
       "      <td>We Won&amp;#39;t Make This Mistake Again</td>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>IBM</td>\n",
       "      <td>How We Missed A Winning Trade On IBM--And How ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investigating IBM's Standing In IT Services In...</td>\n",
       "      <td></td>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Investigating IBM's Standing In IT Services In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90's Tech Titans Are Outshining 'Magnificent S...</td>\n",
       "      <td>Companies that have strong cash flows will lik...</td>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>IBM</td>\n",
       "      <td>90's Tech Titans Are Outshining 'Magnificent S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why Humana Shares Are Trading Lower By Over 11...</td>\n",
       "      <td>Shares of Humana Inc. (NYSE: HUM) fell sharply...</td>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Why Humana Shares Are Trading Lower By Over 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S&amp;P 500 Eyes Sixth Green Session, Tesla Tumble...</td>\n",
       "      <td>U.S. stock market gains due to strong economic...</td>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>IBM</td>\n",
       "      <td>S&amp;P 500 Eyes Sixth Green Session, Tesla Tumble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>Earnings Scheduled For July 30, 2020</td>\n",
       "      <td>Companies Reporting Before The Bell • Masterca...</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>TOT</td>\n",
       "      <td>Earnings Scheduled For July 30, 2020 Companies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>13 Energy Stocks Moving In Tuesday's Pre-Marke...</td>\n",
       "      <td>Gainers • Laredo Petroleum, Inc. (NYSE:LPI) st...</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>TOT</td>\n",
       "      <td>13 Energy Stocks Moving In Tuesday's Pre-Marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6800</th>\n",
       "      <td>Earnings Scheduled For May 5, 2020</td>\n",
       "      <td>Companies Reporting Before The Bell L3Harris T...</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>TOT</td>\n",
       "      <td>Earnings Scheduled For May 5, 2020 Companies R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6801</th>\n",
       "      <td>Earnings Scheduled For April 30, 2020</td>\n",
       "      <td>Companies Reporting Before The Bell McDonald&amp;#...</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>TOT</td>\n",
       "      <td>Earnings Scheduled For April 30, 2020 Companie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>'An Outlier Event': Experts React To Oil Price...</td>\n",
       "      <td>June contract WTI crude oil prices plunged ano...</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>TOT</td>\n",
       "      <td>'An Outlier Event': Experts React To Oil Price...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6803 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headline  \\\n",
       "0     How We Missed A Winning Trade On IBM--And How ...   \n",
       "1     Investigating IBM's Standing In IT Services In...   \n",
       "2     90's Tech Titans Are Outshining 'Magnificent S...   \n",
       "3     Why Humana Shares Are Trading Lower By Over 11...   \n",
       "4     S&P 500 Eyes Sixth Green Session, Tesla Tumble...   \n",
       "...                                                 ...   \n",
       "6798               Earnings Scheduled For July 30, 2020   \n",
       "6799  13 Energy Stocks Moving In Tuesday's Pre-Marke...   \n",
       "6800                 Earnings Scheduled For May 5, 2020   \n",
       "6801              Earnings Scheduled For April 30, 2020   \n",
       "6802  'An Outlier Event': Experts React To Oil Price...   \n",
       "\n",
       "                                                summary  created_at ticker  \\\n",
       "0                  We Won&#39;t Make This Mistake Again  2024-01-26    IBM   \n",
       "1                                                        2024-01-26    IBM   \n",
       "2     Companies that have strong cash flows will lik...  2024-01-26    IBM   \n",
       "3     Shares of Humana Inc. (NYSE: HUM) fell sharply...  2024-01-25    IBM   \n",
       "4     U.S. stock market gains due to strong economic...  2024-01-25    IBM   \n",
       "...                                                 ...         ...    ...   \n",
       "6798  Companies Reporting Before The Bell • Masterca...  2020-07-30    TOT   \n",
       "6799  Gainers • Laredo Petroleum, Inc. (NYSE:LPI) st...  2020-06-02    TOT   \n",
       "6800  Companies Reporting Before The Bell L3Harris T...  2020-05-05    TOT   \n",
       "6801  Companies Reporting Before The Bell McDonald&#...  2020-04-30    TOT   \n",
       "6802  June contract WTI crude oil prices plunged ano...  2020-04-21    TOT   \n",
       "\n",
       "                                       headline_summary  \n",
       "0     How We Missed A Winning Trade On IBM--And How ...  \n",
       "1     Investigating IBM's Standing In IT Services In...  \n",
       "2     90's Tech Titans Are Outshining 'Magnificent S...  \n",
       "3     Why Humana Shares Are Trading Lower By Over 11...  \n",
       "4     S&P 500 Eyes Sixth Green Session, Tesla Tumble...  \n",
       "...                                                 ...  \n",
       "6798  Earnings Scheduled For July 30, 2020 Companies...  \n",
       "6799  13 Energy Stocks Moving In Tuesday's Pre-Marke...  \n",
       "6800  Earnings Scheduled For May 5, 2020 Companies R...  \n",
       "6801  Earnings Scheduled For April 30, 2020 Companie...  \n",
       "6802  'An Outlier Event': Experts React To Oil Price...  \n",
       "\n",
       "[6803 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_file)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "df['headline'] = df['headline'].apply(clean_text)\n",
    "df['summary'] = df['summary'].apply(clean_text)\n",
    "df['created_at'] = df['created_at'].apply(extract_date)\n",
    "df['headline_summary'] = df['headline'] + \" \" + df['summary']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f05aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Tokenisation\n",
    "df['tokens'] = df['headline_summary'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d86d83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['filtered_tokens'] = df['tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0f52e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized'] = df['filtered_tokens'].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38759812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df.to_csv('financial_news_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
